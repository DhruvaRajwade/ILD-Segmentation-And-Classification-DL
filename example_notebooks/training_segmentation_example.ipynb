{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np  #Matrix Calculations\n# import pandas as pd\nimport pandas as pd\nimport os\nimport math\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nimport torch\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:45:23.005132Z","iopub.execute_input":"2023-03-13T23:45:23.006236Z","iopub.status.idle":"2023-03-13T23:45:25.976826Z","shell.execute_reply.started":"2023-03-13T23:45:23.006179Z","shell.execute_reply":"2023-03-13T23:45:25.975737Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import Resize\n\nclass NumpyDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n            label = self.transform(label)\n        return (image, label)\n\n    \ndef numpy_to_dataset(images, labels, batch_size=None, shuffle=False, transform=None):\n    # Convert numpy arrays to PyTorch tensors\n    images = torch.from_numpy(images).float()\n    labels = torch.from_numpy(labels).long()\n\n    # Create dataset from tensors\n    dataset = Dataset(images, labels, transform)\n\n    if batch_size is not None:\n        # Create dataloader from dataset\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n        return dataset, dataloader\n    else:\n        return dataset    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:45:31.710657Z","iopub.execute_input":"2023-03-13T23:45:31.711510Z","iopub.status.idle":"2023-03-13T23:45:31.969247Z","shell.execute_reply.started":"2023-03-13T23:45:31.711464Z","shell.execute_reply":"2023-03-13T23:45:31.968217Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Above is the data_helpers.py code, use it to process your data. I have already processed my data and saved the dataset, which I am loading below.","metadata":{}},{"cell_type":"code","source":"train_data=torch.load('/kaggle/input/final-lung-lesion/train_dataset_lung.pt')\n\nval_data=torch.load('/kaggle/input/final-lung-lesion/val_dataset_lung.pt')\ntrain_dataloader = DataLoader(train_data, batch_size=10, shuffle=True)\nval_dataloader=DataLoader(val_data,batch_size=10, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:45:37.126639Z","iopub.execute_input":"2023-03-13T23:45:37.127305Z","iopub.status.idle":"2023-03-13T23:46:05.975497Z","shell.execute_reply.started":"2023-03-13T23:45:37.127262Z","shell.execute_reply":"2023-03-13T23:46:05.974248Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Defining the model(s)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n\ndef init_weights(net, init_type='normal', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n            if init_type == 'normal':\n                init.normal_(m.weight.data, 0.0, gain)\n            elif init_type == 'xavier':\n                init.xavier_normal_(m.weight.data, gain=gain)\n            elif init_type == 'kaiming':\n                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            elif init_type == 'orthogonal':\n                init.orthogonal_(m.weight.data, gain=gain)\n            else:\n                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n            if hasattr(m, 'bias') and m.bias is not None:\n                init.constant_(m.bias.data, 0.0)\n        elif classname.find('BatchNorm2d') != -1:\n            init.normal_(m.weight.data, 1.0, gain)\n            init.constant_(m.bias.data, 0.0)\n\n    print('initialize network with %s' % init_type)\n    net.apply(init_func)\n\nclass conv_block(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(conv_block,self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass up_conv(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(up_conv,self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n\t\t    nn.BatchNorm2d(ch_out),\n\t\t\tnn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        x = self.up(x)\n        return x\n\nclass Recurrent_block(nn.Module):\n    def __init__(self,ch_out,t=2):\n        super(Recurrent_block,self).__init__()\n        self.t = t\n        self.ch_out = ch_out\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n\t\t    nn.BatchNorm2d(ch_out),\n\t\t\tnn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        for i in range(self.t):\n\n            if i==0:\n                x1 = self.conv(x)\n            \n            x1 = self.conv(x+x1)\n        return x1\n        \nclass RRCNN_block(nn.Module):\n    def __init__(self,ch_in,ch_out,t=2):\n        super(RRCNN_block,self).__init__()\n        self.RCNN = nn.Sequential(\n            Recurrent_block(ch_out,t=t),\n            Recurrent_block(ch_out,t=t)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n\n    def forward(self,x):\n        x = self.Conv_1x1(x)\n        x1 = self.RCNN(x)\n        return x+x1\n\n\nclass single_conv(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(single_conv,self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass Attention_block(nn.Module):\n    def __init__(self,F_g,F_l,F_int):\n        super(Attention_block,self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n            )\n        \n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self,g,x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1+x1)\n        psi = self.psi(psi)\n\n        return x*psi\n\n\nclass U_Net(nn.Module):\n    def __init__(self,img_ch=1,output_ch=12):\n        super(U_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4,d5),dim=1)\n        \n        d5 = self.Up_conv5(d5)\n        \n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1\n\n\nclass R2U_Net(nn.Module):\n    def __init__(self,img_ch=1,output_ch=12,t=2):\n        super(R2U_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.Upsample = nn.Upsample(scale_factor=2)\n\n        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n\n        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n        \n        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n        \n        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n        \n        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n        \n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n        \n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.RRCNN1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.RRCNN2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.RRCNN3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.RRCNN4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.RRCNN5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_RRCNN5(d5)\n        \n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_RRCNN4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_RRCNN3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_RRCNN2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1\n\n\n\nclass AttU_Net(nn.Module):\n    def __init__(self,img_ch=1,output_ch=12):\n        super(AttU_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        x4 = self.Att5(g=d5,x=x4)\n        d5 = torch.cat((x4,d5),dim=1)        \n        d5 = self.Up_conv5(d5)\n        \n        d4 = self.Up4(d5)\n        x3 = self.Att4(g=d4,x=x3)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        x2 = self.Att3(g=d3,x=x2)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        x1 = self.Att2(g=d2,x=x1)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1\n\n\nclass R2AttU_Net(nn.Module):\n    def __init__(self,img_ch=1,output_ch=12,t=2):\n        super(R2AttU_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.Upsample = nn.Upsample(scale_factor=2)\n\n        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n\n        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n        \n        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n        \n        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n        \n        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n        \n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n        \n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.RRCNN1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.RRCNN2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.RRCNN3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.RRCNN4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.RRCNN5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        x4 = self.Att5(g=d5,x=x4)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_RRCNN5(d5)\n        \n        d4 = self.Up4(d5)\n        x3 = self.Att4(g=d4,x=x3)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_RRCNN4(d4)\n\n        d3 = self.Up3(d4)\n        x2 = self.Att3(g=d3,x=x2)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_RRCNN3(d3)\n\n        d2 = self.Up2(d3)\n        x1 = self.Att2(g=d2,x=x1)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_RRCNN2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:47:08.853781Z","iopub.execute_input":"2023-03-13T23:47:08.854573Z","iopub.status.idle":"2023-03-13T23:47:08.924744Z","shell.execute_reply.started":"2023-03-13T23:47:08.854528Z","shell.execute_reply":"2023-03-13T23:47:08.923569Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"The Loss Function (CrossEntropy in this case)","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\n\n\nclass CrossEntropy2d(nn.Module):\n\n    def __init__(self, size_average=True, ignore_label=1):\n        super(CrossEntropy2d, self).__init__()\n        self.size_average = size_average\n        self.ignore_label = ignore_label\n\n    def forward(self, predict, target, weight=None):\n        \"\"\"\n            Args:\n                predict:(n, c, h, w)\n                target:(n, h, w)\n                weight (Tensor, optional): a manual rescaling weight given to each class.\n                                           If given, has to be a Tensor of size \"nclasses\"\n        \"\"\"\n        assert not target.requires_grad\n        assert predict.dim() == 4\n        assert target.dim() == 3\n        n, c, h, w = predict.size()\n        n1, h1, w1 = target.size()\n        target_mask = (target >= 0) * (target != self.ignore_label)\n        target = target[target_mask]\n        if not target.data.dim():\n            return Variable(torch.zeros(1))\n        predict = predict.transpose(1, 2).transpose(2, 3).contiguous()\n        predict = predict[target_mask.view(n, h, w, 1).repeat(1, 1, 1, c)].view(-1, c)\n        loss = F.cross_entropy(predict, target, weight=weight, size_average=self.size_average)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:47:31.809902Z","iopub.execute_input":"2023-03-13T23:47:31.810318Z","iopub.status.idle":"2023-03-13T23:47:31.823408Z","shell.execute_reply.started":"2023-03-13T23:47:31.810279Z","shell.execute_reply":"2023-03-13T23:47:31.822311Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"The below code has two commented lines, uncomment those to resume training from a saved model state_dict.","metadata":{}},{"cell_type":"code","source":"#Save_Dict=(torch.load('/kaggle/input/attn081-val/best_model.pth'))\nmodel=AttU_Net() \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = nn.DataParallel(model)\n    #model.load_state_dict(Save_Dict)\n    model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-6)    ","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:48:36.455207Z","iopub.execute_input":"2023-03-13T23:48:36.456237Z","iopub.status.idle":"2023-03-13T23:48:40.102289Z","shell.execute_reply.started":"2023-03-13T23:48:36.456192Z","shell.execute_reply":"2023-03-13T23:48:40.101038Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}]},{"cell_type":"code","source":"def loss_calc(pred, label, device):\n    criterion = CrossEntropy2d().cuda(device)\n    return criterion(pred, label)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:48:46.019314Z","iopub.execute_input":"2023-03-13T23:48:46.020335Z","iopub.status.idle":"2023-03-13T23:48:46.026230Z","shell.execute_reply.started":"2023-03-13T23:48:46.020278Z","shell.execute_reply":"2023-03-13T23:48:46.024839Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# import torch\nimport csv\nfrom tqdm import tqdm\n#from torch.optim.lr_scheduler import ExponentialLR\n\n#scheduler = ExponentialLR(optimizer, gamma=0.98)\nnum_epochs = 10\npatience = 10\nbest_val_loss = float(\"inf\")\ncounter = 0\n\n# Set the model to training mode\nmodel.train()\n\n# Initialize CSV file for storing results\ncsv_file = open('/kaggle/working/results.csv', 'w', newline='')\ncsv_writer = csv.writer(csv_file)\ncsv_writer.writerow(['Epoch', 'Train Loss', 'Val Loss'])\n\nfor epoch in range(num_epochs):\n    # Use tqdm to display a progress bar during training\n    with tqdm(total=len(train_dataloader)) as pbar:\n        # Initialize variables for computing train loss and accuracy\n        train_loss = 0\n        correct = 0\n        total = 0\n\n        # Iterate over the training data\n        for i, (images, labels) in enumerate(train_dataloader):\n            # Move the data to the device\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Zero the gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images)\n            #print(outputs.shape)\n\n            # Compute the loss\n            loss = loss_calc(outputs, labels[:,0,:,:], device)\n\n            # Backward pass\n            loss.backward()\n\n            # Optimize the model\n            optimizer.step()\n            #scheduler.step()\n\n            # Update train loss and accuracy\n            train_loss += loss.item()\n           \n\n            # Update the progress bar\n            pbar.update(1)\n\n        # Compute train loss and accuracy\n        train_loss /= len(train_dataloader)\n       \n\n        # Perform validation\n        #lrz=scheduler.get_last_lr()\n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for i, (val_images, val_labels) in enumerate(val_dataloader):\n                val_images = val_images.to(device)\n                val_labels = val_labels.to(device)\n                val_outputs = model(val_images)\n                val_loss += loss_calc(val_outputs, val_labels[:,0,:,:], device)\n                _, predicted = torch.max(val_outputs.data, 1)\n                total += val_labels.size(0)\n                correct += (predicted == val_labels[:,0,:,:]).sum().item()\n        val_loss /= len(val_dataloader)\n        v_loss=float(val_loss)\n       \n        print(f'Validation loss for epoch {epoch+1}: {val_loss:.4f}')\n\n        # Write results to CSV file\n        csv_writer.writerow([epoch+1,train_loss, v_loss])\n\n        model.train()\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            counter = 0\n            torch.save(model.state_dict(), 'best_model.pth')\n        else:\n            counter += 1\n            if counter >= patience:\n                print(\"Early stopping\")\n                break\n\n# Close CSV file\ncsv_file.close()","metadata":{"execution":{"iopub.status.busy":"2023-03-13T23:49:34.233930Z","iopub.execute_input":"2023-03-13T23:49:34.235047Z","iopub.status.idle":"2023-03-14T00:07:35.516801Z","shell.execute_reply.started":"2023-03-13T23:49:34.235004Z","shell.execute_reply":"2023-03-14T00:07:35.515751Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 173/173 [01:35<00:00,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 1: 2.0495\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:45<00:00,  1.64it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.08it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 2: 1.8328\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.59it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.08it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 3: 1.7230\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.59it/s]\n100%|██████████| 173/173 [01:38<00:00,  1.98it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 4: 1.6739\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.59it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 5: 1.6232\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.60it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 6: 1.5967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.60it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 7: 1.5624\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.60it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 8: 1.5411\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.60it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 9: 1.5114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.60it/s]\n100%|██████████| 173/173 [01:38<00:00,  2.08it/s]","output_type":"stream"},{"name":"stdout","text":"Validation loss for epoch 10: 1.4946\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 173/173 [01:48<00:00,  1.60it/s]\n","output_type":"stream"}]}]}